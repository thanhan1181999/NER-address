{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate_model_with_validate_data",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HcFJQGJHsRk",
        "outputId": "eb2b24bc-edfb-4b0b-f639-29395a74bc11"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D9G9KinUMl4",
        "outputId": "b8525fbd-2a80-4e76-ac47-de2722ec5af2"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install keras==2.2.5\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=784bcef797eae97aa4b913e7a18bec2afe7f5e59436908d4b3abef4b3795a80c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.5\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-9b2s7dn2\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-9b2s7dn2\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=f313cfc6a68656db39850c645c79e28d498230125d46cd31ff55a35c751b3590\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9vfl3z4b/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4cn6ojhJoIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8934b3-86de-40e2-d873-c01f2d5dba84"
      },
      "source": [
        "from keras.models import Sequential, Model, Input\n",
        "from keras.layers import LSTM, Dense, TimeDistributed, Activation, Bidirectional, Masking, Embedding, Dropout, Flatten, concatenate, Conv1D, MaxPool1D, Lambda, Softmax\n",
        "from keras import backend as K\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_contrib.losses import  crf_loss\n",
        "from keras_contrib.metrics import crf_accuracy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4yZNJ0BIuye"
      },
      "source": [
        "from keras.models import load_model\n",
        "m = load_model(\"/content/drive/MyDrive/model/model-use-rdr-4500-1-1-1-ver2.h5\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kg12gPnX48w"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import argmax"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJDBnDFBJVxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4df7ae-b51a-4ee2-c4f5-c64fb8f6d6d8"
      },
      "source": [
        "char_encode = np.loadtxt('/content/drive/MyDrive/fast_text/val/char_encode.txt')\n",
        "print(char_encode.shape)\n",
        "char_encode = char_encode.reshape(int(char_encode.shape[0]/42), 42, char_encode.shape[1])\n",
        "print(char_encode.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18900, 32)\n",
            "(450, 42, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljh7iSJjJYw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5c3a5f-8e1a-4af2-c10e-8ab5ab6b51ba"
      },
      "source": [
        "# chuyển từ char encode sang char embedding\n",
        "LEN_OF_VOCAB = 137\n",
        "shape = char_encode.shape\n",
        "char_embedd = np.zeros([shape[0],shape[1],shape[2],LEN_OF_VOCAB])\n",
        "for i in range(shape[0]):\n",
        "  for j in range(shape[1]):\n",
        "    for k in range(shape[2]):\n",
        "      char_int = char_encode[i,j,k]\n",
        "      char_int = char_int.astype(np.int64)\n",
        "      onehot = np.zeros(LEN_OF_VOCAB)\n",
        "      onehot[char_int] = 1\n",
        "      char_embedd[i,j,k,:] = onehot\n",
        "\n",
        "print(char_embedd.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(450, 42, 32, 137)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjDcYdy7JbvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf734c1a-64cb-48d1-df7e-e05bbea7c73c"
      },
      "source": [
        "tag = np.loadtxt('/content/drive/MyDrive/fast_text/val/tag_embedd.txt')\n",
        "tag = tag.reshape(int(tag.shape[0]/42), 42, tag.shape[1])\n",
        "print(tag.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(450, 42, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWsDe0wRJdqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d29288b-9cf5-4949-afdc-5aaa41002c1c"
      },
      "source": [
        "word = np.loadtxt('/content/drive/MyDrive/fast_text/val/word_embedd.txt')\n",
        "word = word.reshape(int(word.shape[0]/42), 42, word.shape[1])\n",
        "print(word.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(450, 42, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ2UMExMJUeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def2dbc8-2d6a-4680-bbeb-f24b05832a8f"
      },
      "source": [
        "y_pred = m.predict([char_embedd, word])\n",
        "y_true = tag\n",
        "print(y_pred.shape)\n",
        "print(y_true.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(450, 42, 13)\n",
            "(450, 42, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Mxu-n6MKwf"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SefHoZhuMNSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e553cef5-8bf8-4f49-b527-88146ec4e323"
      },
      "source": [
        "y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], y_pred.shape[2])\n",
        "print(y_pred.shape)\n",
        "y_pred = np.argmax(y_pred,axis=1)\n",
        "print(y_pred.shape)\n",
        "y_pred = y_pred.reshape(int(y_pred.shape[0]/42), 42)\n",
        "print(y_pred.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18900, 13)\n",
            "(18900,)\n",
            "(450, 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgJDJblRMN5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a66752-a894-4f96-df6c-6851b576d82d"
      },
      "source": [
        "y_true = y_true.reshape(y_true.shape[0]*y_true.shape[1], y_true.shape[2])\n",
        "print(y_true.shape)\n",
        "y_true = np.argmax(y_true,axis=1)\n",
        "print(y_true.shape)\n",
        "y_true = y_true.reshape(int(y_true.shape[0]/42), 42)\n",
        "print(y_true.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18900, 13)\n",
            "(18900,)\n",
            "(450, 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUIjfzaxZtd7"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKpCI_BV4qL1"
      },
      "source": [
        "def arr_tag_in_a_tag_sen(sen_pred, sen_true, tag):\n",
        "  j=0\n",
        "  bat_dau=-1\n",
        "  ket_thuc=-1\n",
        "  while j < len(sen_pred):\n",
        "    if sen_true[j]==tag:\n",
        "      bat_dau=j\n",
        "      ket_thuc=j\n",
        "      while sen_true[ket_thuc+1]==1:\n",
        "        ket_thuc=ket_thuc+1\n",
        "      ket_thuc=ket_thuc+1\n",
        "      break\n",
        "    else:\n",
        "        j=j+1\n",
        "\n",
        "  if bat_dau==-1 and ket_thuc==-1:\n",
        "    return 0\n",
        "  \n",
        "  a = sen_pred[bat_dau:ket_thuc]\n",
        "  b = sen_true[bat_dau:ket_thuc]\n",
        "  a = np.array(a)\n",
        "  b = np.array(b)\n",
        "  if (a==b).all():\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q71CvkdUMZrT"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "acc=0\n",
        "false=0\n",
        "\n",
        "homenumber_true = 0\n",
        "street_true = 0 \n",
        "ward_true = 0\n",
        "district_true = 0\n",
        "province_true = 0\n",
        "country_true = 0\n",
        "postcode_true = 0\n",
        "ner_true = 0\n",
        "obj_true = 0\n",
        "obj_feature_true = 0\n",
        "pre_true = 0\n",
        "\n",
        "homenumber_false = 0\n",
        "street_false = 0\n",
        "ward_false = 0\n",
        "district_false = 0\n",
        "province_false = 0\n",
        "country_false = 0\n",
        "postcode_false = 0\n",
        "ner_false = 0\n",
        "obj_false = 0\n",
        "obj_feature_false = 0\n",
        "pre_false = 0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3zHLJLu4wNg"
      },
      "source": [
        "for i in range(len(y_true)):\n",
        "  sen_pred = y_pred[i]\n",
        "  sen_true = y_true[i]\n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 1)==1:\n",
        "    homenumber_true+=1\n",
        "  else:\n",
        "    homenumber_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 1)==1:\n",
        "    homenumber_true+=1\n",
        "  else:\n",
        "    homenumber_false+=1\n",
        "\n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 2)==1:\n",
        "    street_true+=1\n",
        "  else:\n",
        "    street_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 3)==1:\n",
        "    ward_true+=1\n",
        "  else:\n",
        "    ward_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 4)==1:\n",
        "    district_true+=1\n",
        "  else:\n",
        "    district_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 5)==1:\n",
        "    province_true+=1\n",
        "  else:\n",
        "    province_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 6)==1:\n",
        "    country_true+=1\n",
        "  else:\n",
        "    country_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 7)==1:\n",
        "    postcode_true+=1\n",
        "  else:\n",
        "    postcode_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 8)==1:\n",
        "    ner_true+=1\n",
        "  else:\n",
        "    ner_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 9)==1:\n",
        "    obj_true+=1\n",
        "  else:\n",
        "    obj_false+=1\n",
        "  \n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 10)==1:\n",
        "    obj_feature_true+=1\n",
        "  else:\n",
        "    obj_feature_false+=1\n",
        "\n",
        "  if arr_tag_in_a_tag_sen(sen_pred, sen_true, 11)==1:\n",
        "    pre_true+=1\n",
        "  else:\n",
        "    pre_false+=1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dyvq67Z5QR2",
        "outputId": "377c7ccb-765f-4fa3-a5f3-07553c9e9e72"
      },
      "source": [
        "acc = homenumber_true+ street_true+ ward_true+ district_true+ province_true+ country_true+ postcode_true+ ner_true+ obj_true+ obj_feature_true+ pre_true\n",
        "false = homenumber_false+ street_false+ ward_false+ district_false+ province_false+ country_false+ postcode_false+ ner_false+ obj_false+ obj_feature_false+ pre_false\n",
        "print(acc)\n",
        "print(false)\n",
        "print('accuracy = {}'.format(acc/(acc+false)) )\n",
        "ti_le_dung = format(acc/(acc+false)*100, '.2f')\n",
        "print(ti_le_dung)\n",
        "\n",
        "print(\"homenumber : {} true, {} false\".format(homenumber_true, homenumber_false))\n",
        "print(\"street : {} true, {} false\".format(street_true, street_false))\n",
        "print(\"ward : {} true, {} false\".format(ward_true, ward_false))\n",
        "print(\"district : {} true, {} false\".format(district_true, district_false))\n",
        "print(\"province : {} true, {} false\".format(province_true, province_false))\n",
        "print(\"country : {} true, {} false\".format(country_true, country_false))\n",
        "print(\"postcode : {} true, {} false\".format(postcode_true, postcode_false))\n",
        "print(\"ner : {} true, {} false\".format(ner_true, ner_false))\n",
        "print(\"obj : {} true, {} false\".format(obj_true, obj_false))\n",
        "print(\"obj_feature : {} true, {} false\".format(obj_feature_true, obj_feature_false))\n",
        "print(\"pre : {} true, {} false\".format(pre_true, pre_false))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2832\n",
            "2568\n",
            "accuracy = 0.5244444444444445\n",
            "52.44\n",
            "homenumber : 462 true, 438 false\n",
            "street : 293 true, 157 false\n",
            "ward : 155 true, 295 false\n",
            "district : 300 true, 150 false\n",
            "province : 300 true, 150 false\n",
            "country : 142 true, 308 false\n",
            "postcode : 300 true, 150 false\n",
            "ner : 138 true, 312 false\n",
            "obj : 296 true, 154 false\n",
            "obj_feature : 161 true, 289 false\n",
            "pre : 285 true, 165 false\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dRzissoMddN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875fb3e0-7d1d-4fd1-a4de-0aea8b0acf9a"
      },
      "source": [
        "dict = []\n",
        "y_true = y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
        "y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1])\n",
        "for element in y_true:\n",
        "  if element not in dict:\n",
        "    dict.append(element)\n",
        "# print(dict)\n",
        "dict.sort()\n",
        "print(dict)\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_true, y_pred, labels=dict)\n",
        "for i in range(len(cnf_matrix)):\n",
        "  for j in range(len(cnf_matrix)):\n",
        "    cnf_matrix[i][j] = round(cnf_matrix[i][j], 3)\n",
        "print(cnf_matrix)\n",
        "\n",
        "arr_to_cal_predict = []\n",
        "for i in range(len(cnf_matrix)):\n",
        "  tong= 0\n",
        "  for j in range(len(cnf_matrix)):\n",
        "    tong+=cnf_matrix[j][i]\n",
        "  arr_to_cal_predict.append(tong)\n",
        "print(arr_to_cal_predict)\n",
        "# lấy độ predict\n",
        "predict = []\n",
        "for i in range(len(cnf_matrix)):\n",
        "  tong=cnf_matrix[i][i]/arr_to_cal_predict[i]\n",
        "  predict.append(tong)\n",
        "\n",
        "print(\"Độ đo P của từng tag: \")\n",
        "print(predict)\n",
        "print(len(predict))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "[[13501     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    0   301     4     0     0     0     0     0     0     0     0     2\n",
            "      0]\n",
            " [    0     5  1105     2     0     0     0     0     0     0     0     1\n",
            "      0]\n",
            " [    0     0     0   155     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    0     0     0     0   300     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    0     0     0     0     0   300     0     0     0     0     0     0\n",
            "      0]\n",
            " [    0     0     0     0     0     0   142     0     0     0     0     0\n",
            "      0]\n",
            " [    0     0     0     0     0     0     0   300     0     0     0     0\n",
            "      0]\n",
            " [    3     0     0     0     0     0     1     2   484     4     3    12\n",
            "      6]\n",
            " [    0     0     0     0     0     0     0     0     8   555    11     0\n",
            "      1]\n",
            " [    0     2     1     0     0     0     0     0     4    31   330     9\n",
            "      3]\n",
            " [    0     0     2     0     0     0     0     0     5     0     3   463\n",
            "      5]\n",
            " [    0     0     1     0     0     0     0     0     0     0     0    13\n",
            "    820]]\n",
            "[13504, 308, 1113, 157, 300, 300, 143, 302, 501, 590, 347, 500, 835]\n",
            "Độ đo P của từng tag: \n",
            "[0.9997778436018957, 0.9772727272727273, 0.9928122192273136, 0.9872611464968153, 1.0, 1.0, 0.993006993006993, 0.9933774834437086, 0.9660678642714571, 0.940677966101695, 0.9510086455331412, 0.926, 0.9820359281437125]\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uitCUG6Mhl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0491b75d-aaf5-432d-8431-e0be36ab081d"
      },
      "source": [
        "normalized_confusion_matrix = cnf_matrix/cnf_matrix.sum(axis = 1, keepdims = True)\n",
        "for i in range(len(normalized_confusion_matrix)):\n",
        "  for j in range(len(normalized_confusion_matrix)):\n",
        "    normalized_confusion_matrix[i][j] = round(normalized_confusion_matrix[i][j], 3)\n",
        "print(normalized_confusion_matrix)\n",
        "\n",
        "# lấy độ recall\n",
        "recall = []\n",
        "for i in range(len(normalized_confusion_matrix)):\n",
        "  recall.append(normalized_confusion_matrix[i][i])\n",
        "\n",
        "print(\"Độ đo R của từng tag: \")\n",
        "print(recall)\n",
        "print(len(recall))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  0.   ]\n",
            " [0.    0.98  0.013 0.    0.    0.    0.    0.    0.    0.    0.    0.007\n",
            "  0.   ]\n",
            " [0.    0.004 0.993 0.002 0.    0.    0.    0.    0.    0.    0.    0.001\n",
            "  0.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
            "  0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
            "  0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.\n",
            "  0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
            "  0.   ]\n",
            " [0.006 0.    0.    0.    0.    0.    0.002 0.004 0.94  0.008 0.006 0.023\n",
            "  0.012]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    0.014 0.965 0.019 0.\n",
            "  0.002]\n",
            " [0.    0.005 0.003 0.    0.    0.    0.    0.    0.011 0.082 0.868 0.024\n",
            "  0.008]\n",
            " [0.    0.    0.004 0.    0.    0.    0.    0.    0.01  0.    0.006 0.969\n",
            "  0.01 ]\n",
            " [0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.    0.    0.016\n",
            "  0.983]]\n",
            "Độ đo R của từng tag: \n",
            "[1.0, 0.98, 0.993, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94, 0.965, 0.868, 0.969, 0.983]\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHUzSoVKulgw",
        "outputId": "cbf3d942-eda9-4bae-e62e-5a96f77b8c11"
      },
      "source": [
        "# lấy độ F1\n",
        "f1 = []\n",
        "for i in range(len(recall)):\n",
        "  p = predict[i]\n",
        "  r = recall[i]\n",
        "  f1.append(2*p*r/(p+r))\n",
        "\n",
        "print(\"Độ đo F1 của từng tag: \")\n",
        "print(f1)\n",
        "print(len(f1))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Độ đo F1 của từng tag: \n",
            "[0.9998889094612108, 0.9786344635392475, 0.9929061007352699, 0.9935897435897436, 1.0, 1.0, 0.9964912280701755, 0.9966777408637874, 0.9528556767964479, 0.9526837728465336, 0.9076103143872901, 0.9470121372031662, 0.9825177275788409]\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}