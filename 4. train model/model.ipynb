{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOXRbxh4pDe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a930e6-eb5b-485b-eebf-1f991efedde7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0nGi4pspbJr",
        "outputId": "c90faddb-0a04-43c5-8ac4-2f64c90038a1"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install keras==2.2.5\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (56.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-4xrm2phh\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-4xrm2phh\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=c9288589bcecf46ac8cff2b9976b1a75596d15663138239e8e023ce496251e05\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y2to_4md/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZelUzhepIZV"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyew_cs9I3JK",
        "outputId": "e833c306-0968-4cd6-bc08-0425affbd676"
      },
      "source": [
        "char_encode = np.loadtxt('/content/drive/MyDrive/fast_text/train/char_encode.txt')\n",
        "print(char_encode.shape)\n",
        "char_encode = char_encode.reshape(int(char_encode.shape[0]/42), 42, char_encode.shape[1])\n",
        "print(char_encode.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(132174, 32)\n",
            "(3147, 42, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roi007kopkVm",
        "outputId": "dd83928e-33ed-4517-9054-32d4f301604a"
      },
      "source": [
        "tag = np.loadtxt('/content/drive/MyDrive/fast_text/train/tag_embedd.txt')\n",
        "tag = tag.reshape(int(tag.shape[0]/42), 42, tag.shape[1])\n",
        "print(tag.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3147, 42, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NPZBLhNJHpp",
        "outputId": "2a204bc1-e1d4-4f6e-cc10-93e402ec5251"
      },
      "source": [
        "word = np.loadtxt('/content/drive/MyDrive/fast_text/train/word_embedd.txt')\n",
        "word = word.reshape(int(word.shape[0]/42), 42, word.shape[1])\n",
        "print(word.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3147, 42, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9-dIEempjkE"
      },
      "source": [
        "# begin = 0\n",
        "# end = 5957\n",
        "# begin = 5958\n",
        "# end = len(word)\n",
        "# char_encode = char_encode[begin:end+1]\n",
        "# print(char_encode.shape)\n",
        "# tag = tag[begin:end+1]\n",
        "# print(tag.shape)\n",
        "# word = word[begin:end+1]\n",
        "# print(word.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuIiaRIXfOcC",
        "outputId": "e8ca8e9f-ee2b-4252-80b8-9a9dbcceb239"
      },
      "source": [
        "val_char_encode = np.loadtxt('/content/drive/MyDrive/fast_text/val/char_encode.txt')\n",
        "print(val_char_encode.shape)\n",
        "val_char_encode = val_char_encode.reshape(int(val_char_encode.shape[0]/42), 42, val_char_encode.shape[1])\n",
        "print(val_char_encode.shape)\n",
        "val_tag = np.loadtxt('/content/drive/MyDrive/fast_text/val/tag_embedd.txt')\n",
        "val_tag = val_tag.reshape(int(val_tag.shape[0]/42), 42, val_tag.shape[1])\n",
        "print(tag.shape)\n",
        "val_word = np.loadtxt('/content/drive/MyDrive/fast_text/val/word_embedd.txt')\n",
        "val_word = val_word.reshape(int(val_word.shape[0]/42), 42, val_word.shape[1])\n",
        "print(val_word.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18900, 32)\n",
            "(450, 42, 32)\n",
            "(3147, 42, 13)\n",
            "(450, 42, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHEAjpSr8gEt",
        "outputId": "758e2d4b-2535-42a2-8d3b-89b30f34ab04"
      },
      "source": [
        "# chuyển từ char encode sang char embedding\n",
        "LEN_OF_VOCAB = 137\n",
        "shape = char_encode.shape\n",
        "char_embedd = np.zeros([shape[0],shape[1],shape[2],LEN_OF_VOCAB])\n",
        "for i in range(shape[0]):\n",
        "  for j in range(shape[1]):\n",
        "    for k in range(shape[2]):\n",
        "      char_int = char_encode[i,j,k]\n",
        "      char_int = char_int.astype(np.int64)\n",
        "      onehot = np.zeros(LEN_OF_VOCAB)\n",
        "      onehot[char_int] = 1\n",
        "      char_embedd[i,j,k,:] = onehot\n",
        "\n",
        "print(char_embedd.shape)\n",
        "\n",
        "shape = val_char_encode.shape\n",
        "val_char_embedd = np.zeros([shape[0],shape[1],shape[2],LEN_OF_VOCAB])\n",
        "for i in range(shape[0]):\n",
        "  for j in range(shape[1]):\n",
        "    for k in range(shape[2]):\n",
        "      char_int = val_char_encode[i,j,k]\n",
        "      char_int = char_int.astype(np.int64)\n",
        "      onehot = np.zeros(LEN_OF_VOCAB)\n",
        "      onehot[char_int] = 1\n",
        "      val_char_embedd[i,j,k,:] = onehot\n",
        "\n",
        "print(val_char_embedd.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3147, 42, 32, 137)\n",
            "(450, 42, 32, 137)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3Jm6JlxptIA",
        "outputId": "f4a7059c-94a6-4e83-ce2c-1cda3165bc18"
      },
      "source": [
        "from keras.models import Sequential, Model, Input\n",
        "from keras.layers import LSTM, Dense, TimeDistributed, Activation, Bidirectional, Masking, Embedding, Dropout, Flatten, concatenate, Conv1D, MaxPool1D, Lambda, Softmax\n",
        "from keras import backend as K\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_contrib.losses import  crf_loss\n",
        "from keras_contrib.metrics import crf_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9gtD12ltsmo"
      },
      "source": [
        "# hàm này trả về mảng các số k liên tiếp trong mảng X\n",
        "def arr_tag_in_a_tag_sen(sen_pred, sen_true, tag):\n",
        "  j=0\n",
        "  bat_dau=-1\n",
        "  ket_thuc=-1\n",
        "  while j < len(sen_pred):\n",
        "    if sen_true[j]==tag:\n",
        "      bat_dau=j\n",
        "      ket_thuc=j\n",
        "      while sen_true[ket_thuc+1]==1:\n",
        "        ket_thuc=ket_thuc+1\n",
        "      ket_thuc=ket_thuc+1\n",
        "      break\n",
        "    else:\n",
        "        j=j+1\n",
        "\n",
        "  if bat_dau==-1 and ket_thuc==-1:\n",
        "    return 0\n",
        "  \n",
        "  a = sen_pred[bat_dau:ket_thuc]\n",
        "  b = sen_true[bat_dau:ket_thuc]\n",
        "  a = np.array(a)\n",
        "  b = np.array(b)\n",
        "  if (a==b).all():\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxGOx2JLSRS1"
      },
      "source": [
        "# def acc1(y_true, y_pred):\n",
        "#   y_true = tf. y_true.numpy()\n",
        "#   y_pred = y_pred.numpy()\n",
        "#   y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], y_pred.shape[2])\n",
        "#   y_pred = np.argmax(y_pred,axis=1)\n",
        "#   y_true = y_true.reshape(y_true.shape[0]*y_true.shape[1], y_true.shape[2])\n",
        "#   y_true = np.argmax(y_true,axis=1)\n",
        "#   acc=0\n",
        "#   false=0\n",
        "\n",
        "#   homenumber_true = 0\n",
        "#   street_true = 0 \n",
        "#   ward_true = 0\n",
        "#   district_true = 0\n",
        "#   province_true = 0\n",
        "#   country_true = 0\n",
        "#   postcode_true = 0\n",
        "#   ner_true = 0\n",
        "#   obj_true = 0\n",
        "#   obj_feature_true = 0\n",
        "#   pre_true = 0\n",
        "\n",
        "#   homenumber_false = 0\n",
        "#   street_false = 0\n",
        "#   ward_false = 0\n",
        "#   district_false = 0\n",
        "#   province_false = 0\n",
        "#   country_false = 0\n",
        "#   postcode_false = 0\n",
        "#   ner_false = 0\n",
        "#   obj_false = 0\n",
        "#   obj_feature_false = 0\n",
        "#   pre_false = 0\n",
        " \n",
        "\n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 1)==1:\n",
        "#     homenumber_true+=1\n",
        "#   else:\n",
        "#     homenumber_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 1)==1:\n",
        "#     homenumber_true+=1\n",
        "#   else:\n",
        "#     homenumber_false+=1\n",
        "\n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 2)==1:\n",
        "#     street_true+=1\n",
        "#   else:\n",
        "#     street_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 3)==1:\n",
        "#     ward_true+=1\n",
        "#   else:\n",
        "#     ward_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 4)==1:\n",
        "#     district_true+=1\n",
        "#   else:\n",
        "#     district_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 5)==1:\n",
        "#     province_true+=1\n",
        "#   else:\n",
        "#     province_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 6)==1:\n",
        "#     country_true+=1\n",
        "#   else:\n",
        "#     country_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 7)==1:\n",
        "#     postcode_true+=1\n",
        "#   else:\n",
        "#     postcode_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 8)==1:\n",
        "#     ner_true+=1\n",
        "#   else:\n",
        "#     ner_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 9)==1:\n",
        "#     obj_true+=1\n",
        "#   else:\n",
        "#     obj_false+=1\n",
        "  \n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 10)==1:\n",
        "#     obj_feature_true+=1\n",
        "#   else:\n",
        "#     obj_feature_false+=1\n",
        "\n",
        "#   if arr_tag_in_a_tag_sen(sen_pred, sen_true, 11)==1:\n",
        "#     pre_true+=1\n",
        "#   else:\n",
        "#     pre_false+=1\n",
        "\n",
        "#   acc = homenumber_true+ street_true+ ward_true+ district_true+ province_true+ country_true+ postcode_true+ ner_true+ obj_true+ obj_feature_true+ pre_true\n",
        "#   false = homenumber_false+ street_false+ ward_false+ district_false+ province_false+ country_false+ postcode_false+ ner_false+ obj_false+ obj_feature_false+ pre_false\n",
        "#   print(acc)\n",
        "#   print(false)\n",
        "#   ti_le_dung = format(acc/(acc+false)*100, '.2f')\n",
        "#   return ti_le_dung"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg4hOmaiqACP",
        "outputId": "41c0d568-8c28-4d24-cac5-0cab42b94b3b"
      },
      "source": [
        "num_word = 42\n",
        "num_char = 32\n",
        "num_char_of_a_sen = num_word * num_char\n",
        "char_embedding_dim = 137\n",
        "batch_size = 64\n",
        "output_lenght = 13\n",
        "#===========================================================================================\n",
        "char_input  = Input(shape=(num_word, num_char, char_embedding_dim), name=\"char_input\")\n",
        "char        = TimeDistributed(  Conv1D(filters = 8, kernel_size = 3, padding='same') ) (char_input)\n",
        "char        = TimeDistributed(  Conv1D(filters = 8, kernel_size = 3, padding='same') ) (char)\n",
        "char        = TimeDistributed(  MaxPool1D(pool_size = 2)  )  (char)\n",
        "char        = TimeDistributed(  Conv1D(filters = 16, kernel_size = 3, padding='same') ) (char)\n",
        "char        = TimeDistributed(  Conv1D(filters = 16, kernel_size = 3, padding='same') ) (char)\n",
        "char        = TimeDistributed(  MaxPool1D(pool_size = 2)  )  (char)\n",
        "char_out    = TimeDistributed(  Flatten()   )   (char)\n",
        "#============================================================================================\n",
        "word_input  = Input(shape=(num_word, 300), name=\"word_input\")\n",
        "word_out    = word_input\n",
        "#============================================================================================\n",
        "concatenated = concatenate([char_out, word_out])\n",
        "# main BiLSTM model==========================================================================\n",
        "out     = Bidirectional(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(concatenated)\n",
        "out     = TimeDistributed(Dense(output_lenght))(out)\n",
        "output  = Activation('softmax')(out)\n",
        "# crf = CRF(14, name=\"output\")\n",
        "# output = crf(out)\n",
        "#===========================================================================================\n",
        "m = Model(inputs=[char_input, word_input], outputs=output)\n",
        "plot_model(m, \"/content/drive/MyDrive/model/img/model_.png\", show_shapes=True)\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "# m.compile(optimizer='adam', loss=crf.loss_function, metrics=[crf.accuracy, f1_m])\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, 42, 32, 137)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 42, 32, 8)    3296        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 42, 32, 8)    200         time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 42, 16, 8)    0           time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 42, 16, 16)   400         time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 42, 16, 16)   784         time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 42, 8, 16)    0           time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 42, 128)      0           time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "word_input (InputLayer)         (None, 42, 300)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 42, 428)      0           time_distributed_7[0][0]         \n",
            "                                                                 word_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 42, 128)      252416      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistrib (None, 42, 13)       1677        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 42, 13)       0           time_distributed_8[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 258,773\n",
            "Trainable params: 258,773\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SwK0uH-wDXz"
      },
      "source": [
        "# load model vừa train được với dữ liệu trc vào để train tiếp\n",
        "# from keras.models import load_model\n",
        "# m = load_model(\"/content/drive/MyDrive/model/model-use-rdr-4500-1-1-1.h5\")\n",
        "# m = load_model(\"/content/drive/MyDrive/CPoint model/mdl-last.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_L0YSZPqDuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7f247a-ebf9-4e25-eb5a-c6b23dbeec0c"
      },
      "source": [
        "import keras\n",
        "\n",
        "# cp_callback = keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/CPoint model/mdl-last.h5', verbose=1, save_best_only=True)\n",
        "# es_callback = keras.callbacks.EarlyStopping(monitor='acc', patience=5)\n",
        "\n",
        "# character_train, character_test, word_train, word_test, tag_train, tag_test = train_test_split(char_embedd,word,tag, test_size=0.125)\n",
        "\n",
        "# Train the model with the new callback\n",
        "history = m.fit([char_embedd, word], tag,  \n",
        "          epochs=10,\n",
        "          batch_size = 64,\n",
        "          validation_data=([val_char_embedd, val_word], val_tag),  \n",
        "          # callbacks=[cp_callback,es_callback]\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 3147 samples, validate on 450 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "3147/3147 [==============================] - 32s 10ms/step - loss: 1.1898 - acc: 0.7050 - val_loss: 0.7596 - val_acc: 0.7670\n",
            "Epoch 2/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.6135 - acc: 0.8025 - val_loss: 0.4278 - val_acc: 0.8668\n",
            "Epoch 3/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.3446 - acc: 0.8889 - val_loss: 0.2492 - val_acc: 0.9178\n",
            "Epoch 4/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.2167 - acc: 0.9305 - val_loss: 0.1644 - val_acc: 0.9499\n",
            "Epoch 5/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.1442 - acc: 0.9552 - val_loss: 0.1067 - val_acc: 0.9665\n",
            "Epoch 6/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.0951 - acc: 0.9723 - val_loss: 0.0688 - val_acc: 0.9812\n",
            "Epoch 7/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.0621 - acc: 0.9836 - val_loss: 0.0422 - val_acc: 0.9895\n",
            "Epoch 8/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.0422 - acc: 0.9898 - val_loss: 0.0285 - val_acc: 0.9931\n",
            "Epoch 9/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.0312 - acc: 0.9927 - val_loss: 0.0215 - val_acc: 0.9946\n",
            "Epoch 10/10\n",
            "3147/3147 [==============================] - 29s 9ms/step - loss: 0.0248 - acc: 0.9942 - val_loss: 0.0171 - val_acc: 0.9957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-nuBg0Zlkwl"
      },
      "source": [
        "m.save(\"/content/drive/MyDrive/model/model-use-rdr-4500-1-1-1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNdqnA41Lve7"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# # list all data in history\n",
        "# print(history.history.keys())\n",
        "# # summarize history for accuracy\n",
        "# plt.plot(history.history['acc'])\n",
        "# plt.plot(history.history['val_acc'])\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()\n",
        "# # summarize history for loss\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfMg-pOHij17"
      },
      "source": [
        "# from keras.models import load_model\n",
        "# dependencies = {\n",
        "#     'recall_m': recall_m,\n",
        "#     'precision_m':precision_m,\n",
        "#     'f1_m':f1_m\n",
        "# }\n",
        "# custom_objects=dependencies\n",
        "# m = load_model(\"/content/drive/MyDrive/CPoint model/mdl-last_only_address.h5\",custom_objects=dependencies)\n",
        "# m = load_model(\"/content/drive/MyDrive/CPoint model/mdl-last.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xKIRra9FSWd"
      },
      "source": [
        "# y_pred = m.predict([character_test, word_test])\n",
        "# y_true = tag_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLO-AKKTGA3y"
      },
      "source": [
        "# print(y_pred.shape)\n",
        "# print(y_true.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTMHHZzmVkca"
      },
      "source": [
        "# from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWuU2fjHVr8O"
      },
      "source": [
        "# y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], y_pred.shape[2])\n",
        "# print(y_pred.shape)\n",
        "# y_pred = np.argmax(y_pred,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ_94sRcfjsY"
      },
      "source": [
        "# y_true = y_true.reshape(y_true.shape[0]*y_true.shape[1], y_true.shape[2])\n",
        "# print(y_true.shape)\n",
        "# y_true = np.argmax(y_true,axis=1)\n",
        "# print(y_true.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLM1DD-wf3VD"
      },
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "# acc=0\n",
        "# false=0\n",
        "# for i in range(len(y_true)):\n",
        "#   if y_true[i]!=0:\n",
        "#     if y_true[i]==y_pred[i]:\n",
        "#       acc+=1\n",
        "#     else:\n",
        "#       false+=1\n",
        "# print(acc)\n",
        "# print(false)\n",
        "# print('accuracy = {}'.format(acc/(acc+false)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MouOTlsniGMT"
      },
      "source": [
        "# dict = []\n",
        "# for element in y_true:\n",
        "#   if element not in dict:\n",
        "#     dict.append(element)\n",
        "# print(dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCBB3zlwhKPw"
      },
      "source": [
        "# cnf_matrix = confusion_matrix(y_true, y_pred, labels=dict)\n",
        "# for i in range(len(cnf_matrix)):\n",
        "#   for j in range(len(cnf_matrix)):\n",
        "#     cnf_matrix[i][j] = round(cnf_matrix[i][j], 3)\n",
        "# print(cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER-UGVhxhEOq"
      },
      "source": [
        "# normalized_confusion_matrix = cnf_matrix/cnf_matrix.sum(axis = 1, keepdims = True)\n",
        "# for i in range(len(normalized_confusion_matrix)):\n",
        "#   for j in range(len(normalized_confusion_matrix)):\n",
        "#     normalized_confusion_matrix[i][j] = round(normalized_confusion_matrix[i][j], 3)\n",
        "# print(normalized_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PELN0yS6gKUD"
      },
      "source": [
        "# arr_to_cal_predict = []\n",
        "# for i in range(len(cnf_matrix)):\n",
        "#   tong= 0\n",
        "#   for j in range(len(cnf_matrix)):\n",
        "#     tong+=cnf_matrix[j][i]\n",
        "#   arr_to_cal_predict.append(tong)\n",
        "# print(arr_to_cal_predict)\n",
        "# # lấy độ predict\n",
        "# predict = []\n",
        "# for i in range(len(cnf_matrix)):\n",
        "#   tong=cnf_matrix[i][i]/arr_to_cal_predict[i]\n",
        "#   predict.append(tong)\n",
        "# print(predict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}